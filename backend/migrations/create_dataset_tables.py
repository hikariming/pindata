#!/usr/bin/env python3
"""
åˆ›å»ºæ•°æ®é›†ç›¸å…³è¡¨çš„è¿ç§»è„šæœ¬
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import create_app
from app.db import db
from app.models.dataset import Dataset, DatasetVersion, DatasetTag, DatasetLike, DatasetDownload


def create_dataset_tables():
    """åˆ›å»ºæ•°æ®é›†ç›¸å…³è¡¨"""
    app = create_app()
    
    with app.app_context():
        try:
            # åˆ›å»ºæ‰€æœ‰æ•°æ®é›†ç›¸å…³è¡¨
            db.create_all()
            print("âœ… æ•°æ®é›†ç›¸å…³è¡¨åˆ›å»ºæˆåŠŸ")
            
            # æ’å…¥ä¸€äº›ç¤ºä¾‹æ•°æ®
            create_sample_data()
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
            db.session.rollback()
        finally:
            db.session.close()


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    try:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        if Dataset.query.first():
            print("ğŸ“‹ æ•°æ®é›†è¡¨å·²æœ‰æ•°æ®ï¼Œè·³è¿‡ç¤ºä¾‹æ•°æ®åˆ›å»º")
            return
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
        datasets = [
            {
                'name': 'Mixture-of-Thoughts',
                'owner': 'open-r1',
                'description': 'A comprehensive dataset for training mixture of expert models with diverse reasoning capabilities.',
                'size': '699MB',
                'downloads': 11300,
                'likes': 140,
                'license': 'MIT',
                'task_type': 'Natural Language Processing',
                'language': 'English',
                'featured': True,
                'tags': ['reasoning', 'mixture-of-experts', 'llm']
            },
            {
                'name': 'SynLogic',
                'owner': 'MiniMaxAI',
                'description': 'Synthetic logical reasoning dataset generated using advanced language models.',
                'size': '49.3MB',
                'downloads': 211,
                'likes': 51,
                'license': 'Apache 2.0',
                'task_type': 'Question Answering',
                'language': 'English',
                'featured': False,
                'tags': ['logic', 'reasoning', 'synthetic']
            },
            {
                'name': 'china-refusals',
                'owner': 'cognitivecomputations',
                'description': 'Dataset focused on AI safety and alignment research with Chinese language examples.',
                'size': '10.1MB',
                'downloads': 302,
                'likes': 25,
                'license': 'CC BY 4.0',
                'task_type': 'Text Classification',
                'language': 'Chinese',
                'featured': False,
                'tags': ['safety', 'alignment', 'chinese']
            }
        ]
        
        for dataset_data in datasets:
            # åˆ›å»ºæ•°æ®é›†
            tags = dataset_data.pop('tags')
            dataset = Dataset(**dataset_data)
            db.session.add(dataset)
            db.session.flush()  # è·å–ID
            
            # æ·»åŠ æ ‡ç­¾
            for tag_name in tags:
                tag = DatasetTag(dataset_id=dataset.id, name=tag_name)
                db.session.add(tag)
            
            # åˆ›å»ºåˆå§‹ç‰ˆæœ¬
            version = DatasetVersion(
                dataset_id=dataset.id,
                version='v1.0',
                pipeline_config={},
                stats={}
            )
            db.session.add(version)
        
        db.session.commit()
        print("âœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºæˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºç¤ºä¾‹æ•°æ®å¤±è´¥: {e}")
        db.session.rollback()


def drop_dataset_tables():
    """åˆ é™¤æ•°æ®é›†ç›¸å…³è¡¨"""
    app = create_app()
    
    with app.app_context():
        try:
            # åˆ é™¤è¡¨çš„é¡ºåºå¾ˆé‡è¦ï¼ˆå¤–é”®ä¾èµ–ï¼‰
            tables_to_drop = [
                'dataset_downloads',
                'dataset_likes', 
                'dataset_tags',
                'dataset_versions',
                'datasets'
            ]
            
            for table_name in tables_to_drop:
                db.session.execute(f"DROP TABLE IF EXISTS {table_name} CASCADE")
            
            db.session.commit()
            print("âœ… æ•°æ®é›†ç›¸å…³è¡¨åˆ é™¤æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ åˆ é™¤è¡¨å¤±è´¥: {e}")
            db.session.rollback()
        finally:
            db.session.close()


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®é›†è¡¨è¿ç§»è„šæœ¬')
    parser.add_argument('--drop', action='store_true', help='åˆ é™¤ç°æœ‰è¡¨')
    parser.add_argument('--create', action='store_true', help='åˆ›å»ºè¡¨')
    
    args = parser.parse_args()
    
    if args.drop:
        drop_dataset_tables()
    
    if args.create or not (args.drop):
        create_dataset_tables() 